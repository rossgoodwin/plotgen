% This is the (pdf)LaTeX source for: 
% Erowid Experience Vaults Report Id: 101638
% Copyright (c) 2014 erowid.org
%
% Please contact copyrights@erowid.org for permission to reproduce.
%
%
% This sourcefile was generated by exp_pdf.pl v.1.36  using Perl version 5.016003 at Wed Nov 12 21:24:55 2014 GMT on Nov 12, 2014

\documentclass[letterpaper,12pt]{article}
\usepackage[letterpaper,left=20mm,right=20mm,bottom=35mm]{geometry}

\setlength{\parindent}{0pt}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}

\usepackage[pdftex]{color,graphicx}
\pdfcompresslevel=9
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.gif}

\usepackage{ifpdf}
\ifpdf
\usepackage{datetime}
\fi

\usepackage{url}

\usepackage{fancyhdr}
\usepackage{hyperref}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[L]{\setlength{\unitlength}{1mm}\begin{picture}(4,0) \put(0,-1){\includegraphics*[width=0.5cm]{/www/erowid.org/experiences/images/erologo_1cm_600dpi_greyscale}} \end{picture} \footnotesize\sffamily Erowid Experience ID: 101638}
\fancyhead[C]{\footnotesize\sffamily LSD microdosing RCT}
\fancyhead[R]{\footnotesize\sffamily by Gwern.net}

\fancyfoot[L]{\footnotesize\sffamily Exp Year: 2012\hspace{0.2cm} Added to Database: Oct 23, 2013\\ Gender of reportee: male\\ \vspace{0.1cm} \scriptsize\sffamily Generated by exp\_pdf.pl v.1.36  using perl \& pdf\LaTeX \\ on Wed Nov 12 21:24:55 2014 GMT.}
\fancyfoot[C]{\\ \vspace{0.5cm} \\ \thepage}
\fancyfoot[R]{\footnotesize\sffamily \url{http://erowid.org/experiences/exp.php?ID=101638} \\ \vspace{0.1cm} \copyright\,2014 by \href{http://www.erowid.org}{erowid.org}}

\fancypagestyle{plain}{
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[L]{\footnotesize\sffamily Exp Year: 2012\hspace{0.2cm} Added to Database: Oct 23, 2013\\ Gender of reportee: male\\ \vspace{0.1cm} \scriptsize\sffamily Generated by exp\_pdf.pl v.1.36  using perl \& pdf\LaTeX \\ on Wed Nov 12 21:24:55 2014 GMT.}
\fancyfoot[R]{\footnotesize\sffamily \url{http://erowid.org/experiences/exp.php?ID=101638} \\ \vspace{0.1cm} \copyright\,2014 by \href{http://www.erowid.org}{erowid.org}}}

\makeatletter
\renewcommand{\fnum@figure}[1]{}
\makeatother


\begin{document}

\ifpdf
\pdfinfo{
/Title (Erowid Experience Vaults Report Id: 101638 Experience Year: 2012)
/Subject (LSD microdosing RCT)
/Author (Gwern.net)
/Creator (pdfLaTeX)
/Producer (erowid.org)
/CreationDate (D:\pdfdate)
/Keywords (LSD )
}
\fi

\section*{\begin{picture}(20,0) \put(-5,-10){\includegraphics*[width=1cm]{/www/erowid.org/experiences/images/erologo_1cm_600dpi_greyscale}} \end{picture} Erowid Experience Vaults Report Id: 101638}

\subsection*{LSD microdosing RCT}
\vspace{-0.2cm}
by \emph{Gwern.net}
\vspace{0.5cm}
\thispagestyle{plain}

\setlength{\parskip}{1ex}
\begin{tabular}[h]{|c|c|c|c|c|}
\hline
Dose:  T+ 0:00 & 12.5 ug & oral & LSD & liquid\\
\hline
\end{tabular}

\vspace{1mm}

\begin{tabular}[h]{|c|c|}
\hline
Body weight: & 0.00 lbs\\
\hline
\end{tabular}

\vspace{2mm}
http://www.gwern.net/LSD\%20microdosing







    Some early experimental studies with LSD suggested that doses of LSD too small to cause any noticeable effects may improve mood and creativity. Prompted by recent discussion of this claim and the purely anecdotal subsequent evidence for it, I decided to run a well-powered randomized blind trial of 3-day LSD microdoses from September 2012 to March 2013. No beneficial effects reached statistical-significance and there were worrisome negative trends. LSD microdosing did not help me.



Intrigued by old scientific results \& many positive anecdotes since, I experimented with `microdosing' LSD - taking doses $\sim$10Î¼g, far below the level at which it causes its famous effects. At this dosage, the anecdotes claim the usual generic spectrum of positive effects on mood, depression, ability to do work, etc. After researching the matter a bit, I discovered that as far as I could tell, since the original experiment in the 1960s, no one had ever done a blind or even a randomized self-experiment on it.



The self-experiment was simple: I calculated how many doses I needed and whether the experiment was worth running, ordered 2 250Î¼g tabs off Silk Road, designed the experiment (I dissolved one in distilled water, put the solution in one jar \& tap water in the other, and took them in pairs of 3-day blocks), ran it, and analyzed it.



The results of my pre-specified analysis:



    Sleep (using my Zeo):

        latency: none (p=0.49)

        total sleep: none (p=0.12)

        number of awakenings: none (p=0.25)



        morning feel: increased (p=0.011)

        There is an increase in `Morning Feel' from 2.6 to 2.9, d=0.42; correcting for performing 7 different tests, this result is not statistically-significant (it does not survive a Bonferroni correction (since 0.011$>$0.057) nor the q-value approach to family-wise correction).

    Mnemosyne flashcard scores: none (p=0.68)

    Mood/productivity: none (d=-0.18; p=0.27)



    Creativity: none (d=-0.19; p=0.28)



I concluded that if anything, the LSD microdosing may have done the opposite of what I wanted.



Given that this is the opposite of almost all microdosing anecdotes and this pattern suggests placebo \& expectancy effects, I strongly urge any future self-experimenters to up their methodological rigor, and especially to blind their doses to avoid both placebo \& nocebo effects. If they fear the consequences of publication, I am willing to host their writeup on this page; my PGP key is available.

Background



I've long been interested in psychedelics for the insights they may offer into our brains:



    `\ldotsWhen I did 2 hits of acid, I had the exact opposite experience of seeing God. The fact that such a tiny amount of a mere chemical could effect my 'soul' so profoundly was proof positive that the soul is completely material. I already believed this intellectually, but this experience solidified this knowledge into my very being. So personally, I would recommended experimenting with a psychedelic or two for those who wish to study Philosophy.' --darius42



But I'd never actually tried any. Besides being illegal and relatively expensive or hard to get, proponents have been clear that a `good trip' requires someone experienced to watch over you and an appropriate environment - neither of which I had available. So it'd always been something to do later, and pure curiosity about the experience was not enough to break my inertia.



I say `curiosity about the experience' because I am dubious about the actual epistemic value of the psychedelic experience; my interest, like William James, is in what I can learn from the experience about myself and religion. The claims made by psychonauts are frequently extravagant and unjustified; the tangible benefits are either unrelated to the truth of the experience (such as lessened anxiety of death), purely internal (what one wants to do with one's life), or true but unrelated to the claims inferred from the experience and verifiable in a non-psychedelic context (the invention of PCR). If one feels at one with everything in the universe and decides to devote his life to feeding starving children, his devotion to charity proves nothing about the universe, and even if the experience were true at face-value, that would not be enough either - if one felt the opposite, that the universe were not one, would that somehow make the starving children OK? Sam Harris takes an approach very much like mine:



    The mere existence of psychedelics would seem to establish the material basis of mental and spiritual life beyond any doubt - for the introduction of these substances into the brain is the obvious cause of any numinous apocalypse that follows. It is possible, however, if not actually plausible, to seize this datum from the other end and argue, and Aldous Huxley did in his classic essay, The Doors of Perception, that the primary function of the brain could be eliminative: its purpose could be to prevent some vast, transpersonal dimension of mind from flooding consciousness, thereby allowing apes like ourselves to make their way in the world without being dazzled at every step by visionary phenomena irrelevant to their survival. Huxley thought that if the brain were a kind of `reducing valve' for `Mind at Large,' this would explain the efficacy of psychedelics: They could simply be a material means of opening the tap.



    \ldotsUnfortunately, Huxley was operating under the erroneous assumption that psychedelics decrease brain activity. However, modern techniques of neuroimaging have shown that these drugs tend to increase activity in many regions of the cortex (and in subcortical structures as well) [Note 1/24/12: a recent study on psilocybin actually lends some support to Huxley's view. --SH] . Still, the action of these drugs does not rule out dualism, or the existence of realms of mind beyond the brain - but then nothing does. This is one of the problems with views of this kind: They appear to be unfalsifiable. [Physicalism, by contrast, could be easily falsified. If science ever established the existence of ghosts, or reincarnation, or any other phenomenon which would place the human mind (in whole or in part) outside the brain, physicalism would be dead. The fact that dualists can never say what would count as evidence against their views makes this ancient philosophical position very difficult to distinguish from religious faith.]



    Of course, the brain does filter an extraordinary amount of information from consciousness. And, like many who have taken these drugs, I can attest that psychedelics certainly throw open the gates. Needless to say, positing the existence of a `Mind at Large' is more tempting in some states of consciousness than in others. And the question of which view of reality we should privilege is, at times, worth considering. But these drugs can also produce mental states that are best viewed in clinical terms as forms of psychosis. As a general matter, I believe we should be very slow to make conclusions about the nature of the cosmos based upon inner experience - no matter how profound these experiences seem.



The potential `mystical experience' or `encounter with God' has considerable interest for me, though. Even back when I was a very young child, I have always been atheistic; at first, because religions didn't seem like very good explanations of the world, but then because I read through various scriptures \& the Bible \& higher Biblical criticism \& philosophy books without finding anything convincing1. I always wondered whether my disbelief was due to reasoned grounds as I claimed, or a simple lack of the right experiences: other people seem to have mystical experiences and find prayer satisfactory and believe fervently, and I sporadically hear of converts who have `road to Damascus' experiences (like SF author John C. Wright hallucinating and converting to Catholicism after a heart attack). Sporadic hallucinations are a poor ground for belief, as a mental hospital demonstrates, but nevertheless they are quite convincing; it seems that for many, seeing really is believing. Many years later, I have yet to have a mystical or religious or `peak' experience which could either convert me or leave me unmoved, and thus empirically settle the issue as to why I am an atheist - absence of experience, or reasoned belief? Hence, it is tempting to force the issue. (If you have a psilocybin-induced hallucination of God and then become a theist, that's a good piece of evidence that stuff like the argument from evil or argument from silence weren't why you were an atheist. And so if you were claiming previously that they were, you were either lying or badly mistaken.) Thomas Nagel: ('A Philosopher Defends Religion')



    It is illuminating to have the starkness of the opposition between Plantinga's theism and the secular outlook so clearly explained. My instinctively atheistic perspective implies that if I ever found myself flooded with the conviction that what the Nicene Creed says is true, the most likely explanation would be that I was losing my mind, not that I was being granted the gift of faith. From Plantinga's point of view, by contrast, I suffer from a kind of spiritual blindness from which I am unwilling to be cured.



Everything I've heard or read is consistent with what such experiences seem to be: the brain in a very unusual state, malfunctioning in many respects and perhaps functioning better in a few other respects. No one expects to discover a new truth about the universe in the throes of delirium tremens or amphetamine psychosis - isn't it parsimonious to extend this to psychedelics as well? If there were some `truthiness' to the states, I had to think: of the many thousands of mind-altering substances investigated over the centuries, it would be quite remarkable if the few which grant access to new truths were also the very same ones which produce pleasant or enjoyable trips!



So the trip itself is of little direct value, but the 3 categories of effects I outlined are. Everyone talks about Openness (see later) and creativity in relation to psychedelics (eg. Wired/discussion). I would offer a more concrete analogy: creativity is a kind of optimization activity like simulated annealing in which one searches through a vast number of possibilities for the right thing. (This seems to be similar to James L. Kent's views.) In simulated annealing, we can think of the possibilities as a fitness landscape dotted with mountains and valleys, and we are trying to find the lowest point; we start at random points, and jump around randomly and see how low we wind up. How big are our jumps? This is the `temperature'. The temperature starts high, since we may be a very long way away from the lowest point, but as we get lower and closer to the sea, we turn down the temperature and start making small jumps so we don't jump right back onto a mountain or something like that. (Imagine looking through a dictionary: you flip through whole chunks to get the letter right, then you start flipping through pages so you don't overshoot, and finally you read through an individual page.) The temperature has to change, or we will waste a lot of time and may never find our target: if the temperature is always high, no sooner have we found an excellent candidate than we have jumped half a continent away, but if it's always low, we will literally inch around and not find the low point a few miles away. Simulated annealing itself has been applied to neural networks, so it may be more than just an analogy to say our brains do something similar. At first you brainstorm, generating myriads of disparate ideas, but you focus on a few candidates, brainstorm variants, and begin carefully fine-tuning them. You hope you don't spend too much time tinkering that you miss your deadline, but also that you don't spend too little time brainstorming that you miss some brilliant elegant solution.



And LSD? Perhaps doses large enough that you become so `creative' that you start seeing what is not there are analogous to turning the temperature up a thousand degrees: the frantic annealing may hit upon some remote undiscovered great idea (eg. PCR) but this will usually just throw away all one's current good results in favor of some random dreck. Genuine thought and breakthroughs are the pinnacle of human thought, achieved after endless labor and dependent on many dead-ends, bits of knowledge, and intuited truths; randomness seems like it would usually make things much worse2, and in general, pharmacological interventions have little luck improving things. Think of dreams: 4 or 5 a night, hugely random - and only occasionally if ever do they deliver real insight or a valid idea. Isn't it a standard joke that you discover the secret of the universe or the perfect song in a dream, wake up \& write it down, and in the morning it is worthless? It's probably no accident that dreams so rarely produce useful insights and also parts of the brain - particularly parts of the prefrontal cortex - are shut down or operating differently.



    `Once in my life I had a mathematical dream which proved correct. I was twenty years old. I thought, my God, this is wonderful, I won't have to work, it will all come in dreams! But it never happened again.' --Stanislaw Ulam3



Microdosing



But if we turned up the temperature just a few degrees, we might wind up burning our cake, but then again we might cook it to perfection. Theoretical speculation, of course, but with some plausibility to it.



The old research literature is mixed but suggests that LSD doesn't do much under 20Î¼g. Nonetheless, when I read `The Heretic' about James Fadiman's ideas about `micro-dosing' and an earlier interview as well as Vice piece (I later read his The Psychedelic Explorer's Guide), and that it seemed to work well for a variety of people, the old musings came back to mind. A psychedelic LSD dose is 100Î¼g+, and Fadiman's recommended micro-doses 10Î¼g. That puts micro-doses well into the sub-hallucinatory range, and removes most of my safety concerns (since even if there were problems with chronic LSD consumption, `the dose makes the poison'). Certainly it sounds good:



    `Micro-dosing turns out to be a totally different world,' Fadiman extolled. `As someone said, the rocks don't glow, even a little bit. But what many people are reporting is, at the end of the day, they say, `That was a really good day.' You know, that kind of day when things kind of work. You're doing a task you normally couldn't stand for two hours, but you do it for three or four. You eat properly. Maybe you do one more set of reps. Just a good day. That seems to be what we're discovering.' Elsewhere Fadiman has been more specific about the logbooks he's received. One physician reported that micro-dosing got him `in touch with a deep place of ease and beauty.' A vocalist said she could better hear and channel music. In general, study participants functioned normally in their work and relationships, Fadiman has said, but with increased focus, creativity, and emotional clarity. Until he releases his data archive in a comprehensive manner, it is, of course, not possible to scrutinize the validity of his claim\ldots'I just got a report from someone who did this for six weeks,' Fadiman said. `And his question to me was, 'Is there any reason to stop?'' More laughter throughout the hall, another adjustment of bifocals\ldotsit also allows him to follow the recommendation of a longtime, now-deceased friend, Albert Hofmann, who, according to Fadiman, called micro-dosing `the most under-researched area of psychedelics.'



Fadiman was part of the team which ran the Psychedelics in problem-solving experiment, administering 50Î¼g doses of LSD - close, albeit not identical, to microdosing levels - to people working on unsolved technical problems, while they tried thinking about the problems again; they apparently often solved them. There are many fans of LSD microdosing in the relevant Bluelight.ru \& Longecity \& Reddit 1/2/3/4 \& Silk Road forum discussions (though others wonder about tolerance after repeated microdoses). Further, LSD used to be popular in Silicon Valley and used by many computing pioneers (see What the Dormouse Said, Markoff 2005).



None of this, however is particularly strong evidence. To address them in order:



    the original experiment had unavoidable flaws4; for example:

        the problem-solving experiment's n was small; drawing estimates from the methodological, statistical, \& meta-analytic literature, we'd expect something like 19 active days are desirable, so 190+Î¼g are needed; this can be diluted into an evenly divisible amount like 19ml of water and then 1ml extracted each day. 3 days seems to be the maximum that most microdosing enthusiasts consider a dose active for, so there shouldn't be issues with tolerance or carryover. I ran this design by Dr. Fadiman, who did not object.



VitaCat's Mayan tabs were advertised as 250Î¼g, and I diluted the remaining tab into 20ml of water, so nominally each 1ml dose would have 12.5ug of LSD, which is at least twice the level (5Î¼g) a number of people have claimed benefits from microdosing, so even if the tab was overstated by 100Î¼g, the dose should still be enough to produce any effects.



I took one additional step: temporarily suspending my lithium self-experiment. There are many mostly-negative opinions online about the interactions of LSD \& lithium, although most commenters seem to be talking about therapeutic doses of lithium - which are 10-15x larger than the 10mg of lithium orotate which I may have been taking if it wasn't a placebo week. (It later turned out that it was indeed a placebo week so my precaution was unnecessary.) But there is no point in risking the described negative effects or the weakening of the trip, so 2 weeks before, the experiment was paused. Obviously I can't prove that this is sufficient, but I think it was enough: I was taking 10mg orotate every other day (on average) and the anecdotes which caused me to place it on hold were from people taking psychiatric doses which are closer to 500mg, and they generally seem to think that the effect of lithium didn't last for months (which is consistent with the fairly fast metabolism of lithium in the body, $\sim$24 hour half-life); as well, I stopped it weeks before the trip, which went fine, which was itself a week before starting microdosing. So for the lithium to have been a problem, one would have to postulate that the levels of lithium, already 2 orders of magnitude below those claimed to cause problems, did not noticeably interfere with the trip, but somehow did interfere with results spread over 6 months afterwards.



The listed benefits are to mood, productivity, and creativity. We might also want to check other metrics to see if any LSD benefit came at a cost. So I will use my usual metrics plus a new creativity one:



    Zeo sleep data (primarily: latency, total sleep, number of awakenings, morning feel)

    I expect little or no effect on these 4 metrics, or the more obscure ones like sleep composition (light/REM/deep percentages). Two-tailed tests.



    Spaced repetition performance

    Average grade of cards reviewed on a given day; I expect no effect or a benefit (the simulated annealing analogy sounds like it might also work for memory). One-tailed.



    mood/productivity self-rating: 1-5

    3 is a normal day, 2 below-average, 4 a very good day, 5 fantastic etc. The major prediction of the microdose theory is that mood/productivity/creativity will increase, so the final analysis should exploit our prior and use a one-tailed test that the ratings will increase (since higher=better).



    creativity rating: 1-3

    Similar. This is not a metric I currently track, but would be a new one. One-tailed.



    active/placebo prediction

    A prediction recorded at the end of each block on PredictionBook.com; this is not a dependent variable, but a check for whether there is a reliably noticeable subjective effect.



    Before/after Openness to experience questionnaires



    Openness is one of the Big Five personality traits, roughly linked with creativity, interest in novelty and variety; while Conscientiousness (think self-discipline \& hard-work) tends to increase with age, Openness seems to decrease. Personality traits, like IQ, are notoriously hard to change \& predictive of many things about a person. MacLean et al 2011, a rare RCT of psilocybin, found that Openness was still increased a few percentage points $>$1 year after dosing. (While not that large in magnitude, MacLean et al 2011 compares it with the reduction in Openness over 4 decades and increase from successful antidepressants or substance abuse treatment.) The effect seemed to be driven by those reporting a mystical experience; despite identical starting Openness, those reporting a non-mystical experience seemed to see theirs fall. The study has many weaknesses, but is still the best such study I know.



    Since to maximize effectiveness, any full trip should be taken before micro-dosing, this suggest 3 samples: before-trip, after-trip, after-micro-dosing.



    My first long Big Five survey result (using Personality Project) in early 2012 put my Openness at the 87^th percentile; the second, 2 days after the trip, was identical (87th percentile). Since I had no mystic experience, this is consistent with MacLean et al 2011's analysis. A third followup in March 2013, after the microdosing experiment, put me at the 93rd percentile (needless to say, the confidence intervals for all 3 overlap due to the percentile ranking being based on relatively few questions: $\sim$6 for each personality factor).



We don't need to worry about time-of-day effects. The LSD microdoses were at similar times each day (right after getting up). All the dependent variables were generally recorded/done at consistent times, except for the spaced repetition scores since I sometimes reviewed in the afternoon, but I've already investigated time-of-day effects in my spaced repetition performance and they are trivially small both in my dataset \& in a multi-million-review dataset drawn from thousands of Mnemosyne users.

Limitations



There are 3 major potential problems with this experiment: the results may not generalize beyond me, the tabs may not have contained substantial levels of LSD, and the LSD may have degraded while being stored.

Validity



The first problem is inherent to the design and cannot be fixed without other people (who are not me) running comparable experiments. When n=1, as it does here, you are dealing with results that may be of high internal validity which means that inside the experiment, the conclusion of the analysis is (in this case, `I did not benefit in these specific ways from LSD microdosing'), but it is difficult or impossible to know what the external validity is ('people do not benefit in these specific ways from LSD microdosing'). This is a general problem with my nootropics self-experiments. I am not very optimistic that there will be any replications of this experiment: it seems no one else has tried this in the 60 years or so since LSD was banned, anyone who does so may not publish their results, and most people are not as patient as I am in running self-experiments.



Now, we can still speculate about what how my results might generalize to other people. If LSD microdosing worked for only a small fraction of the population, where are all the negative anecdotes? You see some negative ones, sure, but very few in general (I'd guess well under 10\% of anecdotes). Is there any reason to expect there to be a lot of variation from person to person? Does the fact that I tripped without issue bear on the issue and suggest I would be a `responder' if microdosing did work? Which does one consider more plausible: that my n=1 datapoint is explained by interpersonal variation and I just happened to both blind it and be the unlucky guy who naturally doesn't benefit, or that interpersonal variation is irrelevant and the difference between my datapoint and the anecdotes is related to the randomization \& blinding? Personally, I see stuff like placebo effects all the time in research (in fact, you could argue that my dual n-back meta-analysis is about demonstrating that simple expectancy effects can be worth $>$6 points on IQ tests), and so I don't just consider the second explanation to be possible, I consider it to be the default explanation. For me, anecdotes about supplements are considered placebo/expectancy/non-randomization/publication-bias/underpowered/biased-recall/etc until proven innocent.

Dosage

Any



The next question is, how can I be sure I got LSD? A black market is not exactly a lab-quality supplier.



The answer is that I cannot be sure, any more than anyone getting LSD from a non-lab source (which is everyone) can be sure. All I can say is that the seller, VitaCat, was reputable; the Avengers regularly tested wares to keep sellers honest and VitaCat's premium Mayan tabs passed the lab tests twice and even up until the end in October 2013 his LSD was considered one of, if not the, best LSD on SR, and very strong as he claimed6; in general, the FBI reported high quality levels for their purchases of LSD among other drugs; the price was not too good to be true (quite the opposite); the physical small size of the tabs meant that it had to be some highly psychoactive chemical; my trip using one tab matched reports of LSD trips very closely (and in particular trip reports used claimed doses of $>$150Î¼g), and did not match the RC trip descriptions I've read; there was no bitter taste indicative of possible alternative hallucinogens; and so on. Personally, I would be very surprised if what I bought was not LSD.



Lab testing is not available in the USA (as of 2003) according to Erowid, and EcstasyData will not test LSD ('we can not reliably identify [LSD] because of the many isomers and related chemicals that look similar in a mass spectrometer') or report dose estimates - not that I was keen on paying \$100, waiting 3+ weeks, and using up a tab or two. (The LSD Avengers apparently had access to lab tests in the Netherlands.) I decided to also not Ehrlich test because I could not afford the 5-tab purchase (when the LSD Avengers call VitaCat a `premium' or `elite' seller, they weren't kidding), and all an Ehrlich test could tell me was whether there was any alkaloid chemical in it (which was something I could figure out for myself just by taking a tab), and not even whether it was LSD, and not the dose - which is what I actually needed to know. If I had been able to afford more tabs, I probably would've done a test anyway (it would at least have reassured me I wasn't getting an RC), but I only had 2 tabs. I needed 1 for the microdoses, and 1 to trip with, so\ldots Between tripping and testing, it was an easy choice.

Useful dose?



Drugs typically follow dose-response relationships of some sort, sometimes with interesting shapes like the U-curve of the Yerkes-Dodson law for stimulants. Is it possible that the results might be due to falling into a bad place in LSD microdosing's curve, whatever it is?



It's possible that doses might be an issue. But my problem is that even with a dose-response curve, I should have seen something in the results. Generally, biological `thresholds' aren't some magic binary switch where 10Î¼g does nothing whatsoever and 11Î¼g is day and night difference - they're just slopes that incline faster in that region. They do not look like binary circuits where at 10Î¼g they do absolutely nothing and then at 15Î¼g go to the moon. If I saw zero positive effects, on a large sample size, at 10-12Î¼g, why would I expect a huge difference on 25Î¼g especially when the original evidence for LSD microdosing is so weak and questionable? If 15Î¼g was better than 12, then I should have observed something like a medium effect. If 20Î¼g was better than 12, I should have observed something like a small-medium effect. If 30Î¼g was best, I should have seen signs of a small effect, possibly not statistically-significant, but clear point-value shifts. I observed none of that. VitaCat's tab should've been no lower than 200Î¼g, which would still yield 19 microdoses well above the apparent threshold of 5Î¼g; even if it was just 100Î¼g, that would still be above 5Î¼g per microdose.



I am also suspicious of this response because there is no solid evidence of what the dose-response curve would be for microdosing, even just the basic shape, much less specific dose levels that someone could tell me that my dose was all wrong and worthless. And it's such a convenient fully-general excuse, a no true Scotsman: `XÎ¼g didn't work for you? Must've taken the wrong dose! Try again with [more/less]!' (But one man's modus ponens is another man's modus tollens\ldots)



Try again? Well, it is the obvious second experiment, trying multiple levels of doses (eg. 1, 2, and 3ml doses). But I'm not doing a second one: it took something like 6 months to get any level of certainty with the dose I was using, and if I bought more tabs, then that's even more opportunity to argue that I bought bunk LSD or that the tabs differed in dose etc. Given that I didn't see any benefits, I simply cannot justify taking more time to explore a potential supplement which failed the first test. It doesn't begin to pass the cost-benefit/VoI test for me.



I suggest that anyone trying their own experiment also try multiple dosages. But only if they are already blinding \& randomizing. Not every methodological improvement is of equal value.

Degradation



Having gotten LSD, could the LSD have then been destroyed in preparation or storage? For example, in the comments, a Jessica Darko claims:



    But more damaging is that the drug degrades quickly and is very sensitive to its environment. It degrades in the presence of oxygen, heat and light. A common house fridge provides all three- the door is opened at least once a day (to get your dose) letting light in. The container is open to the air which provides oxygen, and while a fridge is cool, it is does not absolutely prevent degradation of the drug due to heat. I've seen storage recommendations for this drug involving sealed, light opaque containers, kept frozen in an icebox and the admonition that this will only preserve it for a few weeks.



If freezing cannot store safely LSD for more than a few weeks, then clearly it is hopeless to expect microdoses to last the few months of the experiment.



LSD does have a reputation for being fragile. However, Darko's claims seem to be entirely false and an excellent example of proving too much. If LSD really did degrade within weeks under the most optimal conditions (and presumably just days under more normal conditions), how did anyone ever consume LSD? Drug supply chains do not operate so fast that they can whisk LSD from the chemist to the user in just a few days. If LSD really did degrade within days, how did anyone ever buy LSD off SR? We can read about LSD distribution chains in places like in the trial transcripts for William Leonard Pickard and there is no indication of LSD requiring ultra-fast delivery or being ultra-time-sensitive. No one in any of the forum threads or web pages on LSD microdosing states that breakdown is a concern if stored in the dark or refrigerated (as I did); Fadiman does not mention it as a concern in his book, and he did not mention it as a potential issue when I sent him the experiment design with time-scale. If the claim was even remotely true, it is difficult to see how Earth \& Fire Erowid could find a vial of LSD which `After 55 years, stored at varying room temperatures, the LSD seemed to be fully potent.' Alexander Shulgin remarks in TiHKAL that `As a salt, in water, cold, and free from air and light exposure, it [LSD] is stable indefinitely.' And it's difficult to see how Li et al 1998 (to borrow Wikipedia's summary) could reach results like the following:



    A controlled study was undertaken to determine the stability of LSD in pooled urine samples.[71] The concentrations of LSD in urine samples were followed over time at various temperatures, in different types of storage containers, at various exposures to different wavelengths of light, and at varying pH values. These studies demonstrated no significant loss in LSD concentration at 25Â°C [77Â°F] for up to four weeks. After four weeks of incubation, a 30\% loss in LSD concentration at 37Â°C [98.6Â°F] and up to a 40\% at 45Â°C [113Â°F] were observed. Urine fortified with LSD and stored in amber glass or nontransparent polyethylene containers showed no change in concentration under any light conditions. Stability of LSD in transparent containers under light was dependent on the distance between the light source and the samples, the wavelength of light, exposure time, and the intensity of light. After prolonged exposure to heat in alkaline pH conditions, 10 to 15\% of the parent LSD epimerized to iso-LSD. Under acidic conditions, less than 5\% of the LSD was converted to iso-LSD.



Power calculation



The descriptions are that the effects are strong \& noticeable, so a large effect size suggests a small experiment; but with 6 metrics, we will want to correct for multiple comparisons (which need will lower the required p-value in our one-tailed tests). We'll assume a large effect size, p=0.01, and paired/within-subject experimental design7:



library(pwr)

pwr.t.test(d=0.8,type='paired',power=0.80,alternative='greater',sig.level=0.01)



     Paired t test power calculation



              n = 18.47818



19 pairs means 19 active and 19 placebo doses, 38 days total. This does not seem unduly onerous, but note that we're assuming LSD has a strong effect since if we cut the effect size in half to d=0.4 (a medium-small effect) we need 66 pairs or 132 days! (If the effects were oversold so d=0.4 was the correct estimate, and we went with 19 pairs, we would not have an 80\% chance of detecting the effect but rather a 24\% chance. Oh well. `We do what we can, because, we must - for the people who are still alive.')



How we treat individual days will matter: do we average the data for each block of 3 days into a single data point, or do we treat each dose as resulting in 3 data points - the effect on the first day, the lessened effect on the second day, and the weakest effect on the third day? (And then the next dose.) The latter seems to be a better strategy, and so with 250Î¼g we get 25 doses of 10Î¼g, each dose is 3 days so as much as 75 days for active and a similar amount for placebo. (75 pairs gives us a similar power calculation all the way down to d=0.4.)



In retrospect (after observing the trends which didn't reach significance), since I specified 7 metrics, it probably would have been better to be conservative and specify a significance-level of sig.level=(0.05/7) or 0.0071 rather than sig.level=0.05/5 or 0.0100.

VoI



    For background on `value of information' calculations, see the Adderall calculation.



With background, design, and power calculation out of the way, we can calculate costs \& values.



    Cost of regular LSD microdosing



    A check of listings on the Silk Road indicates that 300Î¼g can be bought for 5-6btc or \$45; 300Î¼g translates to 30 doses, or 90 days if I follow the 3-day dose pattern some recommend; the yearly cost of LSD is then 4590365=183. Discounted at 5\% annually, the net-present-value/lifetime-cost of switching to LSD would be 183ln1.05=3,751. We can reuse this figure as the potential benefit of LSD microdoses, since if the effect is positive and large enough to notice, then it seems worth roughly 50 cents a day!



    There are 3 major categories of additional costs: the medical risk one runs during the experiment (principally mental), the legal risk, and the reputational risk.



        Schizophrenia and other issues:

        Earlier, I looked into research bearing on the relation of LSD and Schizophrenia, and concluded that the evidence was most consistent with LSD having small health risks (that is, the damaged or ill sought out all sorts of drugs including LSD, but LSD did not cause the damage or at best caused the illness to surface earlier) with some correlations of psychiatric benefit from use; this was over the general LSD population including brain-frying large doses, so the risk for microdoses ought to be much smaller. Much later it occurred to me that the rarity of using LSD along with sheer small size of LSD actually reduces the risk of consumption compared to many other products, simply because dangerous doses of many contaminants or poisons won't fit: blotters reportedly max out at $\sim$500Î¼g. Compare that with, say, piracetam where people take 0.1.) How much so?



    I did expect the results to turn out positive because there are real effects that have been reported, not only in my little studies, but for the past few thousand years in indigenous societies who of course have experimented with micro-doses and every other conceivable form of use.



    As to how [statistically-]significant the statistical breakout would be - I've not really thought much about it. This was your study and your level of statistical sophistication clearly exceeds my own. I tend to be somewhat suspicious of any study where the statistics are fairly exotic, since I know from watching my graduate students PhD dissertations, that when really simple and almost intuitively obvious statistics don't show results, they start to shop around until they find something that gives them a positive result even if it's a statistic that nobody else seems to know about. I watch statistical consultants assure students that they will find something that will justify hiring them. Is this pure science as God and Descartes would have it? Not in my book but hey, the real world is never as clean as the data derived from it.



            Are you willing to be quoted on any of the above?



    Of course, you are free to quote me in anything you write, and I'm free to complain that I was quoted out of context or anything else I choose to say to cover my tail. But in this case, you did the work - you asked me to review the work - and therefore my review becomes part of the total package.



I did this for much the same reason as I wrote down the exact metrics and analysis in advance: to specify what results are expected, how one will interpret them, and to eliminate the temptation to fudge or modify or spin or self-deceive about any of it.

Analysis

Preparation



Preparing the data:



Needed to extract Mnemosyne scores for the past 175 days; for a multi-level model analysis, I'll want even more days which were neither active nor control so I extract even more days than that (back 451 days). Using a Mnemosyne script in the development repository, I set the time interval:



+++ mnemosyne/mnemosyne/example\_scripts/export\_stats.py 2013-03-10 21:54:04 +0000

@@ -12,7 +12,7 @@

 data\_dir = None

 mnemosyne = Mnemosyne(data\_dir)



-for n in range(-10, 0):

+for n in range(-275, -1):

     start\_of\_day = mnemosyne.database().start\_of\_day\_n\_days\_ago(abs(n))



Then run it, extracting the average grade \& transforming the days I didn't review for R:



./bin/python ./mnemosyne/example\_scripts/export\_stats.py $\backslash$

     | cut -d ` ' -f 2 | sed -e `s/None/NA/' $>$ $\sim$/mnemosyne.csv



In R I read in a hand-trimmed Zeo export (lsd.csv), parse dates, add in the Mnemosyne daily grades, the mood/productivity \& creativity daily self-ratings, and write it all back out:



lsd  if result then log p else log (1-p)) ps



logScore predictions

$\sim$$>$ -13.4685



log 0.50 * fromIntegral (length predictions)

$\sim$$>$ -13.8629



Graphing data



Below are the 8 main dependent variables, depicted over time \& colored by whether it fell in a dose 3-day block or control/placebo block. In descending order of importance:

Daily self-rating of mood+work accomplished, 1-5 (higher is better)Daily self-rating of mood+work accomplished, 1-5 (higher is better)

Daily self-rating of creativity/good-ideas, 1-3 (higher is better)Daily self-rating of creativity/good-ideas, 1-3 (higher is better)

Averaged recall performance of Mnemosyne flashcards, 0-5 (higher is better)Averaged recall performance of Mnemosyne flashcards, 0-5 (higher is better)



The 5 sleep variables:

Number of times awoken in a night as recorded by my Zeo (lower is better)Number of times awoken in a night as recorded by my Zeo (lower is better)

Total minutes spent awake after falling asleep (lower=better)Total minutes spent awake after falling asleep (lower=better)

Daily self-rating about how well-rested I feel immediately upon awakening (higher=better)Daily self-rating about how well-rested I feel immediately upon awakening (higher=better)

Total minutes between putting on Zeo headset \& entering sleep (lower=better)Total minutes between putting on Zeo headset \& entering sleep (lower=better)

Total minutes spent asleep (higher=better)Total minutes spent asleep (higher=better)

Testing the metrics



Results from the multivariate regression:



    Sleep:

        latency: none

        total sleep: none

        number of awakenings: none



        morning feel: increased

        There is an increase in `Morning Feel' from 2.6 to 2.9, d=0.43, p=0.011; correcting for performing 7 different tests, this result is not statistically-significant (it does not survive a Bonferroni correction (since 0.0231$>$0.057) nor the q-value approach to family-wise correction). The post hoc MANOVA confirms that there is heterogeneity between days between days (p=0.036), and it is probably being driven mostly or entirely by the morning feel.

    Flashcard scores: none

    Mood/productivity: none (d=-0.18)

    Creativity: none (d=-0.19)

    active/placebo prediction: see previous section



    Before/after Openness: see previous section



For ease of interpretation, the results of the regression in a table:

Variable 	Effect 	p-value 	Coefficient's sign is\ldots

MP - 	0.14 	0.27 	worse

Creativity - 	0.12 	0.28 	worse

Mnemosyne - 	0.00 	0.68 	worse

Total.Z 	14.3 	0.12 	better

Time.to.Z 	2.04 	0.49 	worse

Time.in.Wake 	2.78 	0.29 	worse

Awakenings 	0.64 	0.25 	worse

Morning.Feel 	0.37 	0.01 	better

Conclusion



Overall, there seems to have been no meaningful effects, and worrisome trends. I will not be investigating LSD microdosing further, as it is highly likely to be a waste of time.

Source code



The full analysis, using a multivariate linear regression followed by MANOVA:



R$>$ lsd  \# filter out baseline

R$>$ lsd  l |t|)

(Intercept)   3.0339     0.0898   33.79   |t|)

(Intercept)   1.4068     0.0734    19.2   |t|)

(Intercept)  3.82558    0.01625  235.40   |t|)

(Intercept)   519.80       6.36   81.67   |t|)

(Intercept)    26.58       2.05   12.95   |t|)

(Intercept)    21.93       1.80   12.17   |t|)

(Intercept)    7.237      0.382   18.96   |t|)

(Intercept)    2.593      0.100   25.92    summary(manova(l))

           Df Pillai approx F num Df den Df Pr($>$F)

LSD         1  0.142     2.17      8    105  0.036

Residuals 112



R$>$ \# MP is the most important metric; what is the effect size (Cohen's d) here?

R$>$ (mean(lsd[lsd\$LSD==1,]\$MP) - mean(lsd[lsd\$LSD==0,]\$MP)) / sd(lsd\$MP)

[1] -0.1782

R$>$ (mean(lsd[lsd\$LSD==1,]\$Creativity) - mean(lsd[lsd\$LSD==0,]\$Creativity)) / sd(lsd\$Creativity)

[1] -0.1921



None of the p-values are greater than the normal cutoff after multiple-correction, although Morning.Feel comes close:



R$>$ p.adjust(c(0.27, 0.28, 0.68, 0.12, 0.49, 0.29, 0.25, 0.011), method='BH')  png(file='$\sim$/wiki/images/nootropics/lsd-totalz.png', width = 780, height = 680)

R$>$ qplot(Date, Total.Z, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-timetoz.png', width = 780, height = 680)

R$>$ qplot(Date, Time.to.Z, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-timeinwake.png', width = 780, height = 680)

R$>$ qplot(Date, Time.in.Wake, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-awakenings.png', width = 780, height = 680)

R$>$ qplot(Date, Awakenings, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-morningfeel.png', width = 780, height = 680)

R$>$ qplot(Date, Morning.Feel, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-mnemosyne.png', width = 780, height = 680)

R$>$ qplot(Date, Mnemosyne, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-mp.png', width = 780, height = 680)

R$>$ qplot(Date, MP, color=LSD, data=lsd)

R$>$ dev.off()

R$>$ png(file='$\sim$/wiki/images/nootropics/lsd-creativity.png', width = 780, height = 680)

R$>$ qplot(Date, Creativity, color=LSD, data=lsd)

R$>$ dev.off()



Microdose effect length



One final detail to go with the previous analysis is to take a look at whether there were issues with 3-day blocks being a bad choice.



I classified by hand each day in the relevant period by how many days distant it was from the preceding LSD microdose (that is, the first day of an LSD block is 0, the second day is 1, the third day is 2, and so on up to 7, and past that I just round down to 7). The idea is that this lets us ask for a linear fit relating MP on days which are n distant from a LSD microdose and see if there's any apparent trend - it may be that we failed to see a statistically-significant relationship because we lumped in all days together.



model1 |t|)

(Intercept)   2.8587     0.0986    29.0    l1 |t|)

(Intercept)   3.2090     0.2980   10.77   |t|)

(Intercept)   1.2435     0.2434    5.11  1.4e-06

LSD           0.0162     0.2155    0.08     0.94

DaysSince     0.0301     0.0428    0.70     0.48



Residual standard error: 0.565 on 111 degrees of freedom

  (13 observations deleted due to missingness)

Multiple R-squared:  0.015, Adjusted R-squared:  -0.00273

F-statistic: 0.846 on 2 and 111 DF,  p-value: 0.432





Response Mnemosyne :



Coefficients:

            Estimate Std. Error t value Pr($>$|t|)

(Intercept)  3.80753    0.05400   70.51   |t|)

(Intercept)   545.47      21.01   25.97   |t|)

(Intercept)    32.69       6.80    4.81  4.8e-06

LSD            -2.91       6.02   -0.48     0.63

DaysSince      -1.13       1.19   -0.94     0.35



Residual standard error: 15.8 on 111 degrees of freedom

  (13 observations deleted due to missingness)

Multiple R-squared:  0.0122,    Adjusted R-squared:  -0.00562

F-statistic: 0.684 on 2 and 111 DF,  p-value: 0.506





Response Time.in.Wake :



Coefficients:

            Estimate Std. Error t value Pr($>$|t|)

(Intercept)   26.155      5.978    4.38  2.7e-05

LSD           -0.639      5.292   -0.12     0.90

DaysSince     -0.779      1.051   -0.74     0.46



Residual standard error: 13.9 on 111 degrees of freedom

  (13 observations deleted due to missingness)

Multiple R-squared:  0.015, Adjusted R-squared:  -0.00275

F-statistic: 0.845 on 2 and 111 DF,  p-value: 0.432





Response Awakenings :



Coefficients:

            Estimate Std. Error t value Pr($>$|t|)

(Intercept)    9.374      1.251    7.49  1.8e-11

LSD           -1.093      1.108   -0.99    0.326

DaysSince     -0.394      0.220   -1.79    0.076



Residual standard error: 2.9 on 111 degrees of freedom

  (13 observations deleted due to missingness)

Multiple R-squared:  0.0396,    Adjusted R-squared:  0.0223

F-statistic: 2.29 on 2 and 111 DF,  p-value: 0.106





Response Morning.Feel :



Coefficients:

            Estimate Std. Error t value Pr($>$|t|)

(Intercept)    2.181      0.330    6.61  1.4e-09

LSD            0.704      0.292    2.41    0.018

DaysSince      0.076      0.058    1.31    0.193



Residual standard error: 0.766 on 111 degrees of freedom

  (13 observations deleted due to missingness)

Multiple R-squared:  0.0701,    Adjusted R-squared:  0.0533

F-statistic: 4.18 on 2 and 111 DF,  p-value: 0.0177



R$>$ summary(manova(l1))

           Df Pillai approx F num Df den Df Pr($>$F)

LSD         1  0.142     2.15      8    104  0.038

DaysSince   1  0.076     1.07      8    104  0.390

Residuals 111



None of the estimates are statistically-significant, but the MANOVA suggests that there's modest evidence that the amount of time since a dose matters. To summarize the results for using DaysSince as well in a neat little table:

Variable 	Effect 	p-value 	Coefficient's sign is\ldots

MP 	-0.03 	0.54 	worse

Creativity 	0.03 	0.48 	better

Mnemosyne 	0.00 	0.73 	

Total.Z 	-4.73 	0.20 	worse

Time.to.Z 	-1.13 	0.35 	better

Time.in.Wake 	-0.78 	0.46 	better

Awakenings 	-0.39 	0.07 	better

Morning.Feel 	0.08 	0.19 	better



Do we get a better fit if we omit days `too far' from the microdose, reasoning that the effects would've stopped? Looking just at MP to keep things simple:



R$>$ for (i in 7:2) ( print(summary(lm(MP $\sim$ DaysSince, data=lsd[!(lsd\$DaysSince$>$=i),]))); )



days removed 	correlation 	p

	+0.03100 	0.13

7th 	+0.00418 	0.90

6,7 	-0.00514 	0.89

5,6,7 	-0.05220 	0.32

4,5,6,7 	-0.06680 	0.35

3,4,5,6,7 	-0.17400 	0.11

2,3,4,5,6,7 	+0.00000 	1.00



Obviously the p-values are meaningless in this application; more importantly, the reversal of coefficient sign and changing coefficient size \& significance don't suggest anything in particular to me about dose period.

Advanced analysis: multi-level models



One of the topics I play around with sometime, although I am very far from mastering them, are multi-level models; you can think of them as linear models which can better handle datasets where there's some sort of grouping or categorizing going on. (The canonical example is student test scores: you could regress on them individually, but you'll get better results if you cluster them by classroom, school, and school district.)



None of the data variables except the `creativity' self-rating were collected just for this LSD microdosing experiment: they all have an extensive baseline before and after the experiment. These LSD-free days can't help us estimate how LSD days looked (how could they?), but using MLMs, they may help us nail down what LSD-free days in general look like and reduce uncertainty in estimating their true mean, which makes the comparison to LSD days a little more accurate.



\# install.packages('lme4')

library(lme4)

lsd  lmer(Time.to.Z $\sim$ LSD + (1|Phase), data=lsd)

Linear mixed model fit by REML

Formula: Time.to.Z $\sim$ LSD + (1 | Phase)

   Data: lsd

  AIC  BIC logLik deviance REMLdev

 1030 1041   -511     1030    1022

Random effects:

 Groups   Name        Variance Std.Dev.

 Phase    (Intercept)   5.12    2.26

 Residual             237.89   15.42

Number of obs: 124, groups: Phase, 1



Fixed effects:

            Estimate Std. Error t value

(Intercept)    26.40       2.99    8.82

LSD             2.03       2.77    0.73



Correlation of Fixed Effects:

    (Intr)

LSD -0.463



R$>$ lmer(Time.in.Wake $\sim$ LSD + (1|Phase), data=lsd)

Linear mixed model fit by REML

Formula: Time.in.Wake $\sim$ LSD + (1 | Phase)

   Data: lsd

  AIC  BIC logLik deviance REMLdev

 1007 1019   -500     1007     999

Random effects:

 Groups   Name        Variance Std.Dev.

 Phase    (Intercept)   4.25    2.06

 Residual             197.56   14.06

Number of obs: 124, groups: Phase, 1



Fixed effects:

            Estimate Std. Error t value

(Intercept)    21.82       2.73    8.00

LSD             2.69       2.52    1.07



Correlation of Fixed Effects:

    (Intr)

LSD -0.463



R$>$ lmer(Awakenings $\sim$ LSD + (1|Phase), data=lsd)

Linear mixed model fit by REML

Formula: Awakenings $\sim$ LSD + (1 | Phase)

   Data: lsd

 AIC BIC logLik deviance REMLdev

 624 636   -308      617     616

Random effects:

 Groups   Name        Variance Std.Dev.

 Phase    (Intercept) 0.184    0.429

 Residual             8.553    2.925

Number of obs: 124, groups: Phase, 1



Fixed effects:

            Estimate Std. Error t value

(Intercept)    7.306      0.567    12.9

LSD            0.419      0.525     0.8



Correlation of Fixed Effects:

    (Intr)

LSD -0.463



Linear mixed model fit by REML

Formula: Morning.Feel $\sim$ LSD + (1 | Phase)

   Data: lsd

 AIC BIC logLik deviance REMLdev

 296 307   -144      283     288

Random effects:

 Groups   Name        Variance Std.Dev.

 Phase    (Intercept) 0.0125   0.112

 Residual             0.5792   0.761

Number of obs: 124, groups: Phase, 1



Fixed effects:

            Estimate Std. Error t value

(Intercept)    2.597      0.148   17.59

LSD            0.339      0.137    2.48



Correlation of Fixed Effects:

    (Intr)

LSD -0.463



\# investigate Morning Feel more closely to get a 95\% CI

R$>$ m  mp  mpm  lmer(Creativity $\sim$ LSD + (1|Phase), data=lsd)

Linear mixed model fit by REML

Formula: Creativity $\sim$ LSD + (1 | Phase)

   Data: lsd

 AIC BIC logLik deviance REMLdev

 220 232   -106      206     212

Random effects:

 Groups   Name        Variance Std.Dev.

 Phase    (Intercept) 0.00629  0.0793

 Residual             0.29930  0.5471

Number of obs: 127, groups: Phase, 1



Fixed effects:

            Estimate Std. Error t value

(Intercept)   1.3750     0.1046   13.15

LSD          -0.1052     0.0971   -1.08



Correlation of Fixed Effects:

    (Intr)

LSD -0.461



As before, the highest t-value even with partial pooling to the extensive baseline data, is for `Morning Feel'. The MLM spits out a 95\% CI for its effect being increasing the score by 0.07-0.61 (0.34 would be an increase of d=0.42, which is nice). In contrast, the original t-test for `Morning Feel' gave a CI of 0.05-0.63; so the pooling gained us a slightly narrower CI.



More importantly, what about mood/productivity (MP)? An ordinary linear model on just the data gives a CI of -0.3765-0.123. The MLM gives instead -0.3773-0.121. So unfortunately, the extra work doesn't noticeably change the conclusion.

External links



    Discussion:

        Hacker News

        Reddit

        Shroomery



    `Are mystical experiences metaphysical evidence?'/'Epistemology and enlightenment' -(David Chapman)



    As opposed to other things, like beautiful - I am still an admirer of the Old Testament's Wisdom literature.



    Bruce Charlton in Psychiatry and the Human Condition on psychedelics:



        Creativity is here seen [by psychedelic proponents] as something to be liberated. It is sometimes claimed that by rendering apparently peak experiences more common and controllable, drugs may allow the attainment of a `higher' form of human evolution. Sorry to be boring, but: Evolutionary theory takes exactly the opposite view to [Aldous] Huxley - instead of humans `naturally' knowing everything and evolving the ability to experience less; biology sees the starting point in insentient, inert matter and regards the capacity to perceive anything at all as having evolved gradually over many millions of years. Knowledge is certainly not out there waiting to burst in on our minds as soon as intoxication lets it through. Rather, the capacity to attain knowledge, to perceive, and to be aware of our perceptions, are all adaptations that have been painstakingly constructed over an evolutionary timescale. Neither is scientific creativity spontaneous, natural or pre-formed; it is attained by constructive human striving - something made, not a spontaneous fact of nature. No scientific breakthroughs have ever come from ignorant and uneducated prodigies who happened to be intoxicated. Neither does creativity in science emerge like a beautiful butterfly breaking from a chrysalis of social convention, rather it is something constructed by efforts and gifts (and luck) - including the efforts and gifts of colleagues. Science requires knowledge and skill as well as the right state of mind.



    



    January 14, 1974, in `Conversations with Gian-Carlo Rota'; as quoted on pg262 of Turing's Cathedral (2012) by George Dyson



    I don't blame them for this, since they were abruptly interrupted by a higher power before they could do anything but a pilot experiment (and barely even that). But the flaws can't be ignored or wished away.



    LSD is neutralized by even small amounts of chlorine; later I learned chlorine is not added to my well, so this precaution was unnecessary.



    An important point, since most ordinary LSD tabs, as measured by the DEA (reported in its Microgram publication) and other sources, are closer to 100Î¼g than 250Î¼g.



    Because this is a cross-over design with repeated AB/BA pairs, I could legitimately treat this as a repeated-measures situation and use a paired t-test. But as it turns out, using a more conservative two-sample t-test was not going to change anything in our conclusion. A paired t-test is more powerful than a two-sample t-test, so when we know that the paired \_t\_t-test turned in non-significant p-values (as they did), we then know what the two-sample tests would say: they will just give even more non-statistically-significant results than the paired did.

\end{document}
